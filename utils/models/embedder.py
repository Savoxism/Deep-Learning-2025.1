from sentence_transformers import SentenceTransformer
import torch
import numpy as np
from typing import List, Union

class EmbeddingModel:
    def __init__(self, model_name="AITeamVN/Vietnamese_Embedding", max_seq_length=2048, device=None):
        """
        Wrapper fpr SentenceTransformer.
        """
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ðŸ”§ Loading Model: {model_name} on {self.device}...")
        
        self.model = SentenceTransformer(model_name, device=self.device)
        self.model.max_seq_length = max_seq_length

    def encode(self, texts: Union[str, List[str]], batch_size=32) -> np.ndarray:
        """
        HÃ m encode chung cho cáº£ document vÃ  query.
        Tráº£ vá» Numpy Array (Ä‘Ã£ normalize) Ä‘á»ƒ tiáº¿t kiá»‡m GPU RAM.
        """
        # Tá»± Ä‘á»™ng xá»­ lÃ½ batching vÃ  progress bar bÃªn trong SentenceTransformer
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=False,
            convert_to_numpy=True,     # Quan trá»ng: Chuyá»ƒn vá» CPU ngay
            normalize_embeddings=True  # Quan trá»ng: DÃ¹ng cosine similarity cáº§n cÃ¡i nÃ y
        )
        return embeddings

    # Giá»¯ láº¡i cÃ¡c alias nÃ y Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i code cÅ© cá»§a báº¡n
    def encode_query(self, query: Union[str, List[str]], batch_size=32) -> np.ndarray:
        return self.encode(query, batch_size=batch_size)

    def encode_documents(self, documents: Union[str, List[str]], batch_size=32) -> np.ndarray:
        # Vá»›i BGE-M3/Vietnamese_Embedding, thÆ°á»ng khÃ´ng cáº§n prefix "passage: "
        # trá»« khi model card yÃªu cáº§u cá»¥ thá»ƒ.
        return self.encode(documents, batch_size=batch_size)

    def encode_queries(self, queries: List[str], batch_size=32) -> np.ndarray:
        return self.encode(queries, batch_size=batch_size)